@article{AFZALI2023100463,
title = {Gradient-Free Kernel Conditional Stein Discrepancy goodness of fit testing},
journal = {Machine Learning with Applications},
volume = {12},
pages = {100463},
year = {2023},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2023.100463},
url = {https://www.sciencedirect.com/science/article/pii/S2666827023000166},
author = {Elham Afzali and Saman Muthukumarana},
keywords = {Goodness-of-fit testing, Kernel Stein Discrepancy, Reproducing Kernel Hilbert Spaces, Kernel Stein Discrepancy for conditional density, Gradient-Free Kernel Stein Discrepancy, Importance sampling},
abstract = {In this study, we propose a gradient-free statistical goodness-of-fit test for determining if a joint sample (xi,yi) is drawn from p(y|x)πx for some density πx given a conditional distribution. This test is an alternative to Kernel Conditional Stein Discrepancy, which require the computation of model derivatives and are therefore impractical for complex statistical models. Our method, known as Gradient-Free Kernel Conditional Stein Discrepancy, does not require the calculation of derivatives, this makes it a great tool for tackling difficult problems such as evaluating the performance of generative models. It is able to detect convergence and divergence with the same level of accuracy as the gradient-based method. We also discuss the application of this test in importance sampling and compare its performance with two other conventional methods.}
}